{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RqvV40E1w4Y1aEdHfZxvHnaAY6JhTnUH",
      "authorship_tag": "ABX9TyP6r0va/6Ig+0S2H4q3OlVl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jesus-Vazquez-A/Tensorflow/blob/main/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "Iq9L6QuVouxS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HHsE8HbCoqzr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "FC-IHw-jpzaO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Load Data*"
      ],
      "metadata": {
        "id": "Styy5E1Yp9ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Datasets/insurence_clearv2.csv\")"
      ],
      "metadata": {
        "id": "Pweifrg8p8JO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After cleaning the data, eliminating outliers that may affect the performance of the algorithm, we will divide the predictor variables and the labels, then create partitions for training data and model evaluation."
      ],
      "metadata": {
        "id": "SXh3fwjXqIlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Split Data*"
      ],
      "metadata": {
        "id": "Kda2V7h5sZkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_inputs_outputs():\n",
        "\n",
        "  X = df.drop(columns = ['charges'])\n",
        "  y = df[['charges']]\n",
        "\n",
        "  return X,y"
      ],
      "metadata": {
        "id": "NR52hfaSqDnJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = load_inputs_outputs()"
      ],
      "metadata": {
        "id": "f2SEkEWrsns7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "mdlho2QNsrGg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size = 0.33,random_state = 42)"
      ],
      "metadata": {
        "id": "T9fW6kgysxAB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *One Hot Transform*"
      ],
      "metadata": {
        "id": "AMrk-rhvuErQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ohe(data):\n",
        "\n",
        "  return pd.get_dummies(data,drop_first = True)"
      ],
      "metadata": {
        "id": "J605RHOdt34j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test = ohe(X_train),ohe(X_test)"
      ],
      "metadata": {
        "id": "j_1IwkBFuI1q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Scaler Data*\n",
        "\n",
        "Because the variables can have different units of measurement, it is recommended to make a scale adjustment so that the variables can be compared with each other."
      ],
      "metadata": {
        "id": "Vr64z4bcs7_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ygqK3EW_s6cY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_x = StandardScaler()\n",
        "scaler_y = StandardScaler()"
      ],
      "metadata": {
        "id": "-rQwoNn-tVce"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_x.fit(X_train)\n",
        "scaler_y.fit(Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLbe45wStc6O",
        "outputId": "30fd1806-2a19-4238-adf0-277aad81e616"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fit method calculates the mean and the standard deviation to later perform the scale adjustment."
      ],
      "metadata": {
        "id": "AJXK7C6luQdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaler = scaler_x.transform(X_train)\n",
        "X_test_scaler = scaler_x.transform(X_test)\n",
        "\n",
        "Y_train_scaler = scaler_y.transform(Y_train)\n",
        "Y_test_scaler = scaler_y.transform(Y_test)"
      ],
      "metadata": {
        "id": "c7K88tleunhe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Array Transform*"
      ],
      "metadata": {
        "id": "veRqoJZbvHtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming the data to numpy arrays makes training faster and the data consumes less memory."
      ],
      "metadata": {
        "id": "0LNUSJiWvuMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def array(x):\n",
        "  return np.asarray(x)"
      ],
      "metadata": {
        "id": "rNE1_Zp_vDwx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaler,X_test_scaler = array(X_train_scaler),array(X_test_scaler)\n",
        "\n",
        "Y_train_scaler,Y_test_scaler = array(Y_train_scaler),array(Y_test_scaler)"
      ],
      "metadata": {
        "id": "B_zYDXAavSTt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Neurolal Networks**"
      ],
      "metadata": {
        "id": "Ppq5uRU-wCAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as tf"
      ],
      "metadata": {
        "id": "Ahw7Zq_LvmBs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ije0V8wwmIX",
        "outputId": "81e2a9b3-9747-4241-cb87-203854b8c444"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *First Model*"
      ],
      "metadata": {
        "id": "wffrKFa3x1oJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.Sequential()\n",
        "model.add(tf.layers.Dense(units = 500,activation = 'relu',input_dim = 9))\n",
        "model.add(tf.layers.Dense(units = 250,activation = 'relu'))\n",
        "model.add(tf.layers.Dense(units = 250,activation = 'relu'))\n",
        "model.add(tf.layers.Dense(units = 1,activation = 'linear'))"
      ],
      "metadata": {
        "id": "pWPW2f_7wK9D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Input layer**: It has 500 neurons and received nine predictor variables.\n",
        "* **Hidden Layers**: Both hidden layers have half the number of neurons.\n",
        "* **Output Layer**: It will be the layer that generates the prediction. In this case, the prediction can only be a single value."
      ],
      "metadata": {
        "id": "fJj9H4BGxI__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'mse',optimizer = 'adam',metrics = ['mse'])"
      ],
      "metadata": {
        "id": "b0MzZvkVx5DR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The lost function for regression cases is the mean square error, the optimizer will be adam, which in most cases works quite well."
      ],
      "metadata": {
        "id": "zFvLJhhjyrId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaler,\n",
        "                    Y_train_scaler,\n",
        "                    validation_data = (X_test_scaler,\n",
        "                                       Y_test_scaler),\n",
        "                    batch_size = 32,\n",
        "                    validation_batch_size = 32,\n",
        "                    epochs = 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFEejNIAyCVp",
        "outputId": "cc931ea9-158d-431a-bd7b-c339f897b87c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "28/28 [==============================] - 3s 10ms/step - loss: 0.1848 - mse: 0.1848 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 2/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 3/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0315 - val_mse: 0.0315\n",
            "Epoch 4/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 5/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0200 - val_mse: 0.0200\n",
            "Epoch 6/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0193 - val_mse: 0.0193\n",
            "Epoch 7/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0189 - val_mse: 0.0189\n",
            "Epoch 8/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0187 - val_mse: 0.0187\n",
            "Epoch 9/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 10/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0195 - val_mse: 0.0195\n",
            "Epoch 11/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 12/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 13/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 14/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 15/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0199 - val_mse: 0.0199\n",
            "Epoch 16/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 17/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 18/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 19/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 20/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0199 - val_mse: 0.0199\n",
            "Epoch 21/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 22/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0192 - val_mse: 0.0192\n",
            "Epoch 23/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 24/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0197 - val_mse: 0.0197\n",
            "Epoch 25/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 26/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 27/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 28/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 29/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 30/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 31/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 32/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 33/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 34/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 35/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 36/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0199 - val_mse: 0.0199\n",
            "Epoch 37/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 38/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 39/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 40/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 41/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0193 - val_mse: 0.0193\n",
            "Epoch 42/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0196 - val_mse: 0.0196\n",
            "Epoch 43/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0197 - val_mse: 0.0197\n",
            "Epoch 44/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 45/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 46/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 47/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 48/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 49/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 50/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 51/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0201 - val_mse: 0.0201\n",
            "Epoch 52/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0201 - val_mse: 0.0201\n",
            "Epoch 53/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 54/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 55/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 56/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 57/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 58/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 59/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 60/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0199 - val_mse: 0.0199\n",
            "Epoch 61/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 62/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 63/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 64/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0201 - val_mse: 0.0201\n",
            "Epoch 65/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 66/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 67/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 68/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 69/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 70/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 71/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 72/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0195 - val_mse: 0.0195\n",
            "Epoch 73/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 74/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 75/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 76/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 77/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 78/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0201 - val_mse: 0.0201\n",
            "Epoch 79/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0193 - val_mse: 0.0193\n",
            "Epoch 80/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 81/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 82/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 83/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 84/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 85/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 86/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 87/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 88/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 89/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 90/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 91/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 92/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 93/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 94/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 95/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 96/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 97/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0200 - val_mse: 0.0200\n",
            "Epoch 98/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 99/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 100/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 101/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 102/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 103/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0199 - val_mse: 0.0199\n",
            "Epoch 104/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 105/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 106/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 107/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 108/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 109/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0201 - val_mse: 0.0201\n",
            "Epoch 110/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 111/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "Epoch 112/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 113/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 114/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0201 - val_mse: 0.0201\n",
            "Epoch 115/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 116/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 117/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 118/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 119/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 120/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 121/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 122/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 123/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 124/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 125/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 126/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 127/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 128/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 129/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 130/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 131/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 132/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 133/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 134/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 135/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 136/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 137/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 138/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 139/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 140/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0295 - val_mse: 0.0295\n",
            "Epoch 141/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 142/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 143/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 144/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 145/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 146/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 147/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 148/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 149/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 150/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 151/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 152/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 153/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 154/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 155/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 156/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 157/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 158/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 159/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 160/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 161/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 162/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 163/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 164/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 165/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 166/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 167/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 168/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 169/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 170/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 171/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 172/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 173/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 174/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 175/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 176/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 177/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 178/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 179/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 180/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 181/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 182/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 183/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 184/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 185/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 186/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 187/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 188/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 189/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 190/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 191/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 192/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 193/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 194/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 195/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 196/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 197/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 198/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 199/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 200/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 201/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 202/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 203/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 204/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 205/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 206/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 207/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 208/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 209/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 210/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 211/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 212/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 213/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 214/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 215/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 216/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 217/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 218/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 219/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 220/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 221/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 222/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 223/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 224/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 225/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 226/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 227/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 228/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 229/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 230/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 231/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 232/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 233/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 234/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 235/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 236/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 237/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 238/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 239/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 240/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 241/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 242/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 243/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 244/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 245/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 246/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 247/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 248/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 249/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 250/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 251/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 252/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 253/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0279 - val_mse: 0.0279\n",
            "Epoch 254/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 255/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 256/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 257/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 258/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 259/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 260/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 261/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 262/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 263/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 264/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 265/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 266/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 267/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 268/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 269/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 270/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 271/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 272/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 273/1000\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 274/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 275/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 276/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 277/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 278/1000\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 279/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 280/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 281/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 282/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 283/1000\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 284/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 285/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 286/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 287/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 288/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 289/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 290/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 291/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 292/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 293/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "Epoch 294/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 295/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 296/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 297/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 298/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 299/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 300/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 301/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 302/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 303/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 304/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 305/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 306/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 307/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 308/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 309/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 310/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 311/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 312/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 313/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 314/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 315/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 316/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 317/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 318/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 319/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 320/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 321/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 322/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 323/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 324/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 325/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 326/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 327/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 328/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 329/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 330/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 331/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 332/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 333/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 334/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 335/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 336/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 337/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 338/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 339/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 340/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 341/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 342/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 343/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 344/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 345/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 346/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 347/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 348/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 349/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 350/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 351/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 352/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 353/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 354/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 355/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 356/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 357/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0267 - val_mse: 0.0267\n",
            "Epoch 358/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 359/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 360/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "Epoch 361/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 362/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 363/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 364/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 365/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 366/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 367/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 368/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 369/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 370/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 371/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 372/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 373/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 374/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 375/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 376/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 377/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 378/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 379/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 380/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 381/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 382/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 383/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 384/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 385/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 386/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 387/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 388/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 389/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 390/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 391/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 392/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 393/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 394/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 395/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 396/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 397/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 398/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 399/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 400/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 401/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 402/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 403/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 404/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 405/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 406/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 407/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 408/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 409/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 410/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 411/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 412/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 413/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 414/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 415/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 416/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 417/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 418/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 419/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 420/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 421/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0262 - val_mse: 0.0262\n",
            "Epoch 422/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 423/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 424/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 425/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 426/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 427/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 428/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 429/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 430/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 431/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 432/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 433/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 434/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 435/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 436/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 437/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 438/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 439/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 440/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 441/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 442/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 443/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 444/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 445/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 446/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 447/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 448/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 449/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 450/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 451/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 452/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 453/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 454/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 455/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 456/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 457/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 458/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 459/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 460/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 461/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 462/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 463/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 464/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 465/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 466/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 467/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 468/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 469/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 470/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 471/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 472/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 473/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 474/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 475/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 476/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 477/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 478/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 479/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 480/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 481/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 482/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 483/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 484/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 485/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 486/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 487/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 488/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 489/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 490/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 491/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 492/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 493/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "Epoch 494/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0261 - val_mse: 0.0261\n",
            "Epoch 495/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 496/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 497/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 498/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 499/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 500/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 501/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 502/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 503/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 504/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 505/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 506/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 507/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 508/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 509/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 510/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 511/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 512/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 513/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 514/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 515/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 516/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 517/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 518/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 519/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 520/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 521/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 522/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 523/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 524/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 525/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 526/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 527/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 528/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 529/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 530/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 531/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 532/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 533/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 534/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 535/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 536/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 537/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 538/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 539/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 540/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 541/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 542/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 543/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 544/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 545/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 546/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 547/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 548/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 549/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 550/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 551/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 552/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 553/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 554/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 555/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 556/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 557/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0270 - val_mse: 0.0270\n",
            "Epoch 558/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 559/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 560/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 561/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 562/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 563/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 564/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 565/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 566/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 567/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 568/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 569/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 570/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 571/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 572/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 573/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 574/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 575/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 576/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 577/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 578/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 579/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 580/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 581/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 582/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 583/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 584/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 585/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 586/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 587/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 588/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "Epoch 589/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 590/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 591/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 592/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 593/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 594/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 595/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 596/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 597/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 598/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 599/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 600/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 601/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 602/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 603/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 604/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 605/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 606/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 607/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 608/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 609/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 610/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 611/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 612/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 613/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 614/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 615/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 616/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 617/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 618/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 619/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 620/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 621/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 622/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 623/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 624/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 625/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 626/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 627/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 628/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 629/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 630/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 631/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 632/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 633/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 634/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 635/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 636/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 637/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 638/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 639/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 640/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 641/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 642/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 643/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 644/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 645/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 646/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 647/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 648/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 649/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 650/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 651/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 652/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 653/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 654/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 655/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 656/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 657/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 658/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 659/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 660/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 661/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 662/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 663/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 664/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 665/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 666/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 667/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 668/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 669/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 670/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 671/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 672/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 673/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 674/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 675/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 676/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 677/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 678/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 679/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 680/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 681/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 682/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 683/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 684/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 685/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 686/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 687/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 688/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 689/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 690/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 691/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 692/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 693/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 694/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 695/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 696/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 697/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 698/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 699/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 700/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 701/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 702/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 703/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 704/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 705/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 706/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 707/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 708/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 709/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 710/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 711/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 712/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 713/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 714/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 715/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 716/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 717/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 718/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 719/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 720/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 721/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 722/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 723/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 724/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 725/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 726/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 727/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 728/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 729/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 730/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 731/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 732/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 733/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 734/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 735/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 736/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 737/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 738/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 739/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "Epoch 740/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 741/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 742/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 743/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 744/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 745/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0261 - val_mse: 0.0261\n",
            "Epoch 746/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 747/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 748/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 749/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 750/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 751/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 752/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 753/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 754/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 755/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 756/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 757/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 758/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 759/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 760/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 761/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 762/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 763/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 764/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 765/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 766/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 767/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 768/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 769/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 770/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 771/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 772/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 773/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 774/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 775/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 776/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 777/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 778/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 779/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 780/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 781/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 782/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 783/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 784/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 785/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 786/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 787/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 788/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 789/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 790/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 791/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 792/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 793/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 794/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 795/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 796/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 797/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 798/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 799/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 800/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 801/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 802/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 803/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 804/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 805/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 806/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 807/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 808/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 809/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 810/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 811/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 812/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 813/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 814/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 815/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 816/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 817/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 818/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 819/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 820/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 821/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 822/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 823/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 824/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 825/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 826/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 827/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 828/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 829/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 830/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 831/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 832/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 833/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 834/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 835/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 836/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 837/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 838/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 839/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 840/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 841/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 842/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 843/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 844/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 845/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 846/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 847/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 848/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 849/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 850/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 851/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "Epoch 852/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 853/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 854/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 855/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 856/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "Epoch 857/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 858/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 859/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 860/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 861/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 862/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 863/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 864/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 865/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 866/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "Epoch 867/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 868/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 869/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 870/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 871/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 872/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 873/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 874/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 875/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 876/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 877/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 878/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 879/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 880/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 881/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 882/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 883/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 884/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 885/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 886/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 887/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 888/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 889/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 890/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 891/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 892/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 893/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 894/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 895/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 896/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 897/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 898/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 899/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 900/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 901/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 902/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 903/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 904/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 905/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 906/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 907/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 908/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 909/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 910/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 911/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0216 - val_mse: 0.0216\n",
            "Epoch 912/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 913/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 914/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 915/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 916/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 917/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 918/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 919/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 920/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 921/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 922/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0226 - val_mse: 0.0226\n",
            "Epoch 923/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 924/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 925/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 926/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 927/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 928/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 929/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 930/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 931/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 932/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 933/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 934/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 935/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 936/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 937/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 938/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 939/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0227 - val_mse: 0.0227\n",
            "Epoch 940/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 941/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 942/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 943/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 944/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 945/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 946/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 947/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 948/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0239 - val_mse: 0.0239\n",
            "Epoch 949/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 950/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 951/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 952/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 953/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 954/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 955/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 956/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 957/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 958/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 959/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 960/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0237 - val_mse: 0.0237\n",
            "Epoch 961/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 962/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 963/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 964/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0248 - val_mse: 0.0248\n",
            "Epoch 965/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 966/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 967/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 968/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 969/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 970/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 971/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 972/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 973/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 974/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 975/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 976/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0244 - val_mse: 0.0244\n",
            "Epoch 977/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0238 - val_mse: 0.0238\n",
            "Epoch 978/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 979/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 980/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 981/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 982/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 983/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0255 - val_mse: 0.0255\n",
            "Epoch 984/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 985/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 986/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 987/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 988/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 989/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0261 - val_mse: 0.0261\n",
            "Epoch 990/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "Epoch 991/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0254 - val_mse: 0.0254\n",
            "Epoch 992/1000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0253 - val_mse: 0.0253\n",
            "Epoch 993/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 994/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0280 - val_mse: 0.0280\n",
            "Epoch 995/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 996/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 997/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0251 - val_mse: 0.0251\n",
            "Epoch 998/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0229 - val_mse: 0.0229\n",
            "Epoch 999/1000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 1000/1000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0237 - val_mse: 0.0237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(style = 'whitegrid')"
      ],
      "metadata": {
        "id": "W9kAbQ9Xzpvl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.subplots(1,1,figsize = (20,8))\n",
        "_ = plt.plot(history.history['mse'],label = 'MSE')\n",
        "_ = plt.plot(history.history['val_mse'],label = 'Validation MSE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "x0ejo3qay7EE",
        "outputId": "454d6eb2-ba67-4a09-aeee-ebbf06d3a5d4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From epoch number 100 there is no significant improvement for the validation data compared to the training data, so the model may have a slight overweight of the data."
      ],
      "metadata": {
        "id": "MlwU1J5u0ANv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Second Model*"
      ],
      "metadata": {
        "id": "VRt3Y-AR0dbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "\n",
        "  model = tf.Sequential([\n",
        "      \n",
        "      tf.layers.Dense(units = 64,activation = 'relu',input_dim = 9),\n",
        "      tf.layers.Dense(units = 32,activation = 'relu'),\n",
        "      tf.layers.Dense(units = 32,activation = 'relu'),\n",
        "      tf.layers.Dropout(rate = 0.2),\n",
        "      tf.layers.Dense(units = 1,activation = 'linear')\n",
        "\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "6DGFusKG0br-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Input layer**: It has 64 neurons and received nine predictor variables.\n",
        "* **Hidden Layers**: Both hidden layers have half the number of neurons.\n",
        "* **Drouput Layer**: Deactivate a percentage of the neurons so that the model forgets irrelevant data that could bias the model.\n",
        "* **Output Layer**: It will be the layer that generates the prediction. In this case, the prediction can only be a single value.\n",
        "\n"
      ],
      "metadata": {
        "id": "HbspRxQq1FoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "qoWuT9ZjCSdZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'mse',optimizer = 'adam',metrics = ['mse'])"
      ],
      "metadata": {
        "id": "R9S6gMzVCLyD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.callbacks.EarlyStopping(patience=5,restore_best_weights=True)"
      ],
      "metadata": {
        "id": "7ijt63aACjuz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **EarlyStopping** function offers an early stop if the loss function does not decrease for the validation data, the model will stop preventing it from overtraining."
      ],
      "metadata": {
        "id": "mZ5LfSRLCyMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scaler,\n",
        "                    Y_train_scaler,\n",
        "                    validation_data = (X_test_scaler,\n",
        "                                       Y_test_scaler),\n",
        "                    batch_size = 32,\n",
        "                    validation_batch_size = 32,\n",
        "                    epochs = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Cjn3JcCbtb",
        "outputId": "f5a56f63-77bc-4722-ed9b-641d554efe60"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/64\n",
            "28/28 [==============================] - 1s 10ms/step - loss: 0.8134 - mse: 0.8134 - val_loss: 0.4779 - val_mse: 0.4779\n",
            "Epoch 2/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2764 - mse: 0.2764 - val_loss: 0.0847 - val_mse: 0.0847\n",
            "Epoch 3/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1059 - mse: 0.1059 - val_loss: 0.0476 - val_mse: 0.0476\n",
            "Epoch 4/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1009 - mse: 0.1009 - val_loss: 0.0386 - val_mse: 0.0386\n",
            "Epoch 5/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0361 - val_mse: 0.0361\n",
            "Epoch 6/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 7/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0737 - mse: 0.0737 - val_loss: 0.0318 - val_mse: 0.0318\n",
            "Epoch 8/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 9/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0301 - val_mse: 0.0301\n",
            "Epoch 10/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0628 - mse: 0.0628 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 11/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0578 - mse: 0.0578 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 12/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 13/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0256 - val_mse: 0.0256\n",
            "Epoch 14/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 15/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 16/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0441 - mse: 0.0441 - val_loss: 0.0258 - val_mse: 0.0258\n",
            "Epoch 17/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0252 - val_mse: 0.0252\n",
            "Epoch 18/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 19/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 20/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 21/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 22/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 23/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 24/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0201 - val_mse: 0.0201\n",
            "Epoch 25/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 26/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0200 - val_mse: 0.0200\n",
            "Epoch 27/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 28/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 29/64\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.0231 - val_mse: 0.0231\n",
            "Epoch 30/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 31/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 32/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 33/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0199 - val_mse: 0.0199\n",
            "Epoch 34/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 35/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 36/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 37/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 38/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0203 - val_mse: 0.0203\n",
            "Epoch 39/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0220 - val_mse: 0.0220\n",
            "Epoch 40/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 41/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0259 - val_mse: 0.0259\n",
            "Epoch 42/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 43/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 44/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 45/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 46/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0200 - val_mse: 0.0200\n",
            "Epoch 47/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0194 - val_mse: 0.0194\n",
            "Epoch 48/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 49/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 50/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0200 - val_mse: 0.0200\n",
            "Epoch 51/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 52/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 53/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 54/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 55/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 56/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0195 - val_mse: 0.0195\n",
            "Epoch 57/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0205 - val_mse: 0.0205\n",
            "Epoch 58/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0206 - val_mse: 0.0206\n",
            "Epoch 59/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0211 - val_mse: 0.0211\n",
            "Epoch 60/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "Epoch 61/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 62/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0235 - val_mse: 0.0235\n",
            "Epoch 63/64\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0196 - val_mse: 0.0196\n",
            "Epoch 64/64\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0210 - val_mse: 0.0210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.subplots(1,1,figsize = (20,8))\n",
        "_ = plt.plot(history.history['mse'],label = 'MSE')\n",
        "_ = plt.plot(history.history['val_mse'],label = 'Validation MSE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "SLqCt8fcD2Fg",
        "outputId": "95d5c3bb-f49a-4d7b-fb04-70a06e9723ba"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From epoch number 29 there is no significant improvement for the lost function of the evaluation data, for which the model decided to stop the training."
      ],
      "metadata": {
        "id": "2CCda3mSEmJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save Model**"
      ],
      "metadata": {
        "id": "qA-yKvLzErNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "2MZE8pulEoY3"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}